= dupd
Jyri J. Virkki <https://github.com/jvirkki[@jvirkki]>
dupd is a file duplicate detection CLI utility.

dupd supports a slightly different approach on dealing with duplicates
than other similar tools I have tried. Other tools tend to fall into
one of these two styles:

1. Tools which produce a long text report and you're on your own. This
works ok but can be overwhelming when the number of files is huge.

2. Tools which are eager (sometimes dangerously overeager) to actively
delete duplicates. I find this far too risky (dupd will never delete
files directly).

While dupd can be used in mode #1 ('dupd report') and it can be sort
of coaxed into mode #2 ('dupd rmsh'), dupd is best when used in an
interactive exploratory style.

- Generate a scan of the entire filesystem first, which dupd saves into an SQLite database.
- Drill down into subdirectories where duplicates live and using the ls/dups/uniques/file operations, reviewing where duplicates are coming from and why.
- Move or remove files around as desired and then analyze other subdirectories.  
- After a few rounds of such cleanup, then re-run a whole scan to refresh the database.

== Supported platforms
The build currently supports Linux, Solaris, OS X and OpenBSD. Other UNIX variants should work with minimal effort. 

See BUILDING.adoc file for notes on building dupd.

== Project goals & objectives
dupd seeks to be fast and efficient. For most file sets it performs better than popular tools such as 'fdupes'.

See http://www.virkki.com/jyri/articles/index.php/duplicate-file-detection-performance/
[this article] for some performance comparisons.

== Quick howto:

% dupd scan --path $HOME   (or whichever path you want to scan)
% dupd report

Read the EXAMPLE.adoc file here for a sample walkthrough of using dupd.

For more information read the USAGE document or run 'dupd help'.
